#!/usr/bin/env python3
"""
åˆ›å»ºKMZæ–‡ä»¶åæµ‹è¯•æ•°æ®é›†
ç”¨äºŽå­—ç¬¦ä¸²åŒ¹é…æ¨¡å—çš„æµ‹è¯•å’ŒéªŒè¯
"""

import json
import csv
from pathlib import Path

def create_test_dataset():
    """åˆ›å»ºæµ‹è¯•æ•°æ®é›†"""
    
    # è¯»å–å®Œæ•´çš„KMZæ–‡ä»¶åˆ†æžç»“æžœ
    with open('kmz_analysis_results.json', 'r', encoding='utf-8') as f:
        analysis_results = json.load(f)
    
    # æå–æµ‹è¯•æ•°æ®é›†
    test_dataset = {
        'metadata': {
            'total_files': analysis_results['total_files'],
            'finished_points_files': len([f for f in analysis_results['detailed_files'] 
                                         if f['pattern_info']['has_finished_points']]),
            'date_range': analysis_results['date_analysis']['date_range'],
            'unique_locations': analysis_results['location_analysis']['unique_locations'],
            'creation_date': '2025-08-31'
        },
        'finished_points_files': [],
        'sample_files': [],
        'location_patterns': {},
        'date_patterns': {}
    }
    
    # æ”¶é›†finished_pointsæ–‡ä»¶
    finished_files = []
    location_patterns = {}
    date_patterns = {}
    
    for file_detail in analysis_results['detailed_files']:
        if file_detail['pattern_info']['has_finished_points']:
            file_info = {
                'filename': file_detail['filename'],
                'location': file_detail['pattern_info']['location_name'],
                'date': file_detail['date_info']['date_8digit'],
                'directory': file_detail['directory'],
                'size': file_detail['size'],
                'full_location_name': file_detail['filename'].split('_finished_points')[0]
            }
            finished_files.append(file_info)
            
            # æŒ‰ä½ç½®åˆ†ç»„
            location = file_info['location']
            if location not in location_patterns:
                location_patterns[location] = []
            location_patterns[location].append(file_info['filename'])
            
            # æŒ‰æ—¥æœŸåˆ†ç»„
            date = file_info['date']
            if date and date not in date_patterns:
                date_patterns[date] = []
            if date:
                date_patterns[date].append(file_info['filename'])
    
    test_dataset['finished_points_files'] = finished_files
    test_dataset['location_patterns'] = location_patterns
    test_dataset['date_patterns'] = date_patterns
    
    # åˆ›å»ºæ ·æœ¬æ•°æ®é›†ï¼ˆæ¯ä¸ªä½ç½®å–å‰5ä¸ªæ–‡ä»¶ï¼‰
    sample_files = []
    for location, files in location_patterns.items():
        sample_files.extend([f for f in finished_files if f['location'] == location][:5])
    
    test_dataset['sample_files'] = sample_files
    
    # ä¿å­˜æµ‹è¯•æ•°æ®é›†
    with open('kmz_test_dataset.json', 'w', encoding='utf-8') as f:
        json.dump(test_dataset, f, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºCSVæ ¼å¼çš„æµ‹è¯•æ•°æ®é›†
    csv_data = []
    for file_info in finished_files:
        csv_data.append({
            'filename': file_info['filename'],
            'location': file_info['location'],
            'full_location_name': file_info['full_location_name'],
            'date': file_info['date'],
            'directory': file_info['directory'],
            'size': file_info['size']
        })
    
    with open('kmz_test_dataset.csv', 'w', newline='', encoding='utf-8') as f:
        if csv_data:
            writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())
            writer.writeheader()
            writer.writerows(csv_data)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"âœ… æµ‹è¯•æ•°æ®é›†åˆ›å»ºå®Œæˆ!")
    print(f"   - æ€»æ–‡ä»¶æ•°: {len(finished_files)}")
    print(f"   - ä½ç½®æ•°é‡: {len(location_patterns)}")
    print(f"   - æ—¥æœŸæ•°é‡: {len(date_patterns)}")
    print(f"   - æ ·æœ¬æ–‡ä»¶æ•°: {len(sample_files)}")
    print(f"   - JSONæ–‡ä»¶: kmz_test_dataset.json")
    print(f"   - CSVæ–‡ä»¶: kmz_test_dataset.csv")
    
    # æ˜¾ç¤ºä½ç½®åˆ†å¸ƒ
    print(f"\nðŸ“ ä½ç½®åˆ†å¸ƒ (top 10):")
    sorted_locations = sorted(location_patterns.items(), key=lambda x: len(x[1]), reverse=True)
    for location, files in sorted_locations[:10]:
        print(f"   {location}: {len(files)} ä¸ªæ–‡ä»¶")
    
    # æ˜¾ç¤ºæ–‡ä»¶åæ¨¡å¼ç¤ºä¾‹
    print(f"\nðŸ“‹ æ–‡ä»¶åæ¨¡å¼ç¤ºä¾‹:")
    for location, files in sorted_locations[:5]:
        print(f"   {location}:")
        for filename in files[:3]:
            print(f"     - {filename}")
        if len(files) > 3:
            print(f"     ... è¿˜æœ‰ {len(files) - 3} ä¸ªæ–‡ä»¶")
        print()
    
    return test_dataset

if __name__ == "__main__":
    dataset = create_test_dataset()
